{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "655ff268",
   "metadata": {},
   "source": [
    "# SocraticFlanT5 - Caption Generation (baseline) | DL2 Project, May 2023\n",
    "---\n",
    "\n",
    "This notebook downloads the images from the validation split of the [MS COCO Dataset (2017 version)](https://cocodataset.org/#download) and the corresponding ground-truth captions and generates captions based on the Socratic model pipeline outlined below. The caption will be generated by the baseline approach:\n",
    "* <span style=\"color:#006400\">**Baseline**</span>: a Socratic model based on the work by [Zeng et al. (2022)](https://socraticmodels.github.io/) where GPT-3 is replaced by [FLAN-T5-xl](https://huggingface.co/docs/transformers/model_doc/flan-t5). \n",
    "\n",
    "In other words, the goal of this jupyter notebook is to reproduce the Socratic Models paper with the Flan-T5 model. This provides a baseline for us to build upon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e331e",
   "metadata": {},
   "source": [
    "## Set-up\n",
    "If you haven't done so already, please activate the corresponding environment by running in the terminal: `conda env create -f environment.yml`. Then type `conda activate socratic`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1503d1d",
   "metadata": {},
   "source": [
    "### Loading the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11989003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package loading\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from transformers import set_seed\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Local imports\n",
    "from scripts.image_captioning import ClipManager, ImageManager, VocabManager, FlanT5Manager, COCOManager\n",
    "from scripts.image_captioning import LmPromptGenerator as pg\n",
    "from scripts.utils import get_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d341a53",
   "metadata": {},
   "source": [
    "### Set seeds for reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a30f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set HuggingFace seed\n",
    "set_seed(42)\n",
    "\n",
    "# Set seed for 100 random images of the MS COCO validation split\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aada75e",
   "metadata": {},
   "source": [
    "## Step 1: Downloading the MS COCO images and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "898c7e8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m imgs_folder \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimgs/val2017/\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      2\u001B[0m annotation_file \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mannotations/annotations/captions_val2017.json\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 4\u001B[0m coco_manager \u001B[38;5;241m=\u001B[39m \u001B[43mCOCOManager\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m coco_manager\u001B[38;5;241m.\u001B[39mdownload_data()\n",
      "File \u001B[0;32m~/PycharmProjects/socraticmodels/scripts/image_captioning.py:28\u001B[0m, in \u001B[0;36mCOCOManager.__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;124;03mdataset: dataset to download\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset_to_download \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimgs\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp://images.cocodataset.org/zips/val2017.zip\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mannotations\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp://images.cocodataset.org/annotations/annotations_trainval2017.zip\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     27\u001B[0m }\n\u001B[0;32m---> 28\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/socraticmodels/scripts/image_captioning.py:44\u001B[0m, in \u001B[0;36mCOCOManager.download_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     40\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03mDownloads the images and annotations of the COCO dataset of interest if the file does not exist.\u001B[39;00m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m folder, url \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset_to_download\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_unzip_delete\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfolder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/socraticmodels/scripts/image_captioning.py:32\u001B[0m, in \u001B[0;36mCOCOManager.download_unzip_delete\u001B[0;34m(self, part, url)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdownload_unzip_delete\u001B[39m(\u001B[38;5;28mself\u001B[39m, part, url):\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(part \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m---> 32\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(part \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.zip\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     34\u001B[0m             f\u001B[38;5;241m.\u001B[39mwrite(response\u001B[38;5;241m.\u001B[39mcontent)\n",
      "File \u001B[0;32m~/miniconda3/envs/socratic/lib/python3.9/site-packages/requests/api.py:73\u001B[0m, in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/socratic/lib/python3.9/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/socratic/lib/python3.9/site-packages/requests/sessions.py:587\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    582\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    585\u001B[0m }\n\u001B[1;32m    586\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 587\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/miniconda3/envs/socratic/lib/python3.9/site-packages/requests/sessions.py:745\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    742\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n\u001B[0;32m--> 745\u001B[0m     \u001B[43mr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\n\u001B[1;32m    747\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "File \u001B[0;32m~/miniconda3/envs/socratic/lib/python3.9/site-packages/requests/models.py:899\u001B[0m, in \u001B[0;36mResponse.content\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    897\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    898\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 899\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter_content\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCONTENT_CHUNK_SIZE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content_consumed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    902\u001B[0m \u001B[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001B[39;00m\n\u001B[1;32m    903\u001B[0m \u001B[38;5;66;03m# since we exhausted the data.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/socratic/lib/python3.9/site-packages/requests/models.py:816\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 816\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    817\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m~/miniconda3/envs/socratic/lib/python3.9/site-packages/urllib3/response.py:628\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp):\n\u001B[0;32m--> 628\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    630\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[1;32m    631\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[0;32m~/miniconda3/envs/socratic/lib/python3.9/site-packages/urllib3/response.py:567\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt, decode_content, cache_content)\u001B[0m\n\u001B[1;32m    564\u001B[0m fp_closed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    566\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error_catcher():\n\u001B[0;32m--> 567\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    568\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    569\u001B[0m         flush_decoder \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/socratic/lib/python3.9/site-packages/urllib3/response.py:533\u001B[0m, in \u001B[0;36mHTTPResponse._fp_read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m buffer\u001B[38;5;241m.\u001B[39mgetvalue()\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    532\u001B[0m     \u001B[38;5;66;03m# StringIO doesn't like amt=None\u001B[39;00m\n\u001B[0;32m--> 533\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m~/miniconda3/envs/socratic/lib/python3.9/http/client.py:463\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    460\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    461\u001B[0m     \u001B[38;5;66;03m# Amount is given, implement using readinto\u001B[39;00m\n\u001B[1;32m    462\u001B[0m     b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mbytearray\u001B[39m(amt)\n\u001B[0;32m--> 463\u001B[0m     n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    464\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmemoryview\u001B[39m(b)[:n]\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[1;32m    465\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    466\u001B[0m     \u001B[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001B[39;00m\n\u001B[1;32m    467\u001B[0m     \u001B[38;5;66;03m# and self.chunked\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/socratic/lib/python3.9/http/client.py:507\u001B[0m, in \u001B[0;36mHTTPResponse.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    502\u001B[0m         b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmemoryview\u001B[39m(b)[\u001B[38;5;241m0\u001B[39m:\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength]\n\u001B[1;32m    504\u001B[0m \u001B[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001B[39;00m\n\u001B[1;32m    505\u001B[0m \u001B[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001B[39;00m\n\u001B[1;32m    506\u001B[0m \u001B[38;5;66;03m# (for example, reading in 1k chunks)\u001B[39;00m\n\u001B[0;32m--> 507\u001B[0m n \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadinto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m n \u001B[38;5;129;01mand\u001B[39;00m b:\n\u001B[1;32m    509\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    510\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    511\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m~/miniconda3/envs/socratic/lib/python3.9/socket.py:704\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    703\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 704\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    706\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "imgs_folder = 'imgs/val2017/'\n",
    "annotation_file = 'annotations/annotations/captions_val2017.json'\n",
    "\n",
    "coco_manager = COCOManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19c54da",
   "metadata": {},
   "source": [
    "## Step 2: Generating the captions via the Socratic pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aab5ad",
   "metadata": {},
   "source": [
    "### Set the device and instantiate managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bcac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to use\n",
    "device = get_device()\n",
    "\n",
    "# Instantiate the clip manager\n",
    "clip_manager = ClipManager(device)\n",
    "\n",
    "# Instantiate the image manager\n",
    "image_manager = ImageManager()\n",
    "\n",
    "# Instantiate the vocab manager\n",
    "vocab_manager = VocabManager()\n",
    "\n",
    "# Instantiate the Flan T5 manager\n",
    "flan_manager = FlanT5Manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f0d924",
   "metadata": {},
   "source": [
    "### Compute place and object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c21e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the place features\n",
    "if not os.path.exists('cache/place_feats.npy'):\n",
    "    # Calculate the place features\n",
    "    place_feats = clip_manager.get_text_feats([f'Photo of a {p}.' for p in vocab_manager.place_list])\n",
    "    np.save('cache/place_feats.npy', place_feats)\n",
    "else:\n",
    "    place_feats = np.load('cache/place_feats.npy')\n",
    "\n",
    "# Calculate the object features\n",
    "if not os.path.exists('cache/object_feats.npy'):\n",
    "    # Calculate the object features\n",
    "    object_feats = clip_manager.get_text_feats([f'Photo of a {o}.' for o in vocab_manager.object_list])\n",
    "    np.save('cache/object_feats.npy', object_feats)\n",
    "else:\n",
    "    object_feats = np.load('cache/object_feats.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59985dbb",
   "metadata": {},
   "source": [
    "### Load images and compute image embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d44faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "approach = 'baseline'\n",
    "\n",
    "img_dic = {}\n",
    "img_feat_dic = {}\n",
    "img_paths = {}\n",
    "# if not os.path.exists(f'{approach}_outputs.csv'):\n",
    "    # N = len(os.listdir(imgs_folder))\n",
    "    # N = 100\n",
    "N = 100\n",
    "random_numbers = random.sample(range(len(os.listdir(imgs_folder))), N)\n",
    "\n",
    "# for ix, file_name in enumerate(os.listdir(imgs_folder)[:N]):\n",
    "for ix, file_name in enumerate(os.listdir(imgs_folder)):\n",
    "     # Consider only image files that are part of the random sample\n",
    "    if file_name.endswith(\".jpg\") and ix in random_numbers:  \n",
    "        # Getting image id\n",
    "        file_name_strip = file_name.strip('.jpg')\n",
    "        match = re.search('^0+', file_name_strip)\n",
    "        sequence = match.group(0)\n",
    "        image_id = int(file_name_strip[len(sequence):])\n",
    "\n",
    "        img_path = os.path.join(imgs_folder, file_name)\n",
    "        img = image_manager.load_image(img_path)\n",
    "        img_feats = clip_manager.get_img_feats(img)\n",
    "        img_feats = img_feats.flatten()\n",
    "        img_paths[image_id] = file_name\n",
    "\n",
    "        img_dic[image_id] = img\n",
    "        img_feat_dic[image_id] = img_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13299759",
   "metadata": {},
   "source": [
    "### Zero-shot VLM (CLIP)\n",
    "We zero-shot prompt CLIP to produce various inferences of an iage, such as image type or the number of people in an image:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b6632d",
   "metadata": {},
   "source": [
    "#### Classify image type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be894f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_types = ['photo', 'cartoon', 'sketch', 'painting']\n",
    "img_types_feats = clip_manager.get_text_feats([f'This is a {t}.' for t in img_types])\n",
    "\n",
    "# Create a dictionary to store the image types\n",
    "img_type_dic = {}\n",
    "for img_name, img_feat in img_feat_dic.items():\n",
    "    sorted_img_types, img_type_scores = clip_manager.get_nn_text(img_types, img_types_feats, img_feat)\n",
    "    img_type_dic[img_name] = sorted_img_types[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3867d",
   "metadata": {},
   "source": [
    "#### Classify number of people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b3b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_texts_bool = ['no people', 'people']\n",
    "ppl_feats_bool = clip_manager.get_text_feats([f'There are {p} in this photo.' for p in ppl_texts_bool])\n",
    "\n",
    "ppl_texts_mult = ['is one person', 'are two people', 'are three people', 'are several people', 'are many people']\n",
    "ppl_feats_mult = clip_manager.get_text_feats([f'There {p} in this photo.' for p in ppl_texts_mult])\n",
    "\n",
    "# Create a dictionary to store the number of people\n",
    "num_people_dic = {}\n",
    "\n",
    "for img_name, img_feat in img_feat_dic.items():\n",
    "    sorted_ppl_texts, ppl_scores = clip_manager.get_nn_text(ppl_texts_bool, ppl_feats_bool, img_feat)\n",
    "    ppl_result = sorted_ppl_texts[0]\n",
    "    if ppl_result == 'people':\n",
    "        sorted_ppl_texts, ppl_scores = clip_manager.get_nn_text(ppl_texts_mult, ppl_feats_mult, img_feat)\n",
    "        ppl_result = sorted_ppl_texts[0]\n",
    "    else:\n",
    "        ppl_result = f'are {ppl_result}'\n",
    "\n",
    "    num_people_dic[img_name] = ppl_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b4549f",
   "metadata": {},
   "source": [
    "#### Classify image place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e318fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_topk = 3\n",
    "\n",
    "# Create a dictionary to store the number of people\n",
    "location_dic = {}\n",
    "for img_name, img_feat in img_feat_dic.items():\n",
    "    sorted_places, places_scores = clip_manager.get_nn_text(vocab_manager.place_list, place_feats, img_feat)\n",
    "    location_dic[img_name] = sorted_places[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf872a1",
   "metadata": {},
   "source": [
    "#### Classify image object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e18f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_topk = 10\n",
    "\n",
    "# Create a dictionary to store the similarity of each object with the images\n",
    "obj_list_dic = {}\n",
    "for img_name, img_feat in img_feat_dic.items():\n",
    "    sorted_obj_texts, obj_scores = clip_manager.get_nn_text(vocab_manager.object_list, object_feats, img_feat)\n",
    "    object_list = ''\n",
    "    for i in range(obj_topk):\n",
    "        object_list += f'{sorted_obj_texts[i]}, '\n",
    "    object_list = object_list[:-2]\n",
    "    obj_list_dic[img_name] = object_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e564fd3",
   "metadata": {},
   "source": [
    "#### Generate captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bdfc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_captions = 50\n",
    "\n",
    "# Set LM params\n",
    "model_params = {'temperature': 0.9, 'max_length': 40, 'do_sample': True}\n",
    "\n",
    "# Create dictionaries to store the outputs\n",
    "prompt_dic = {}\n",
    "sorted_caption_map = {}\n",
    "caption_score_map = {}\n",
    "\n",
    "for img_name in img_dic:\n",
    "    # Create the prompt for the language model\n",
    "    prompt_dic[img_name] = pg.create_baseline_lm_prompt(\n",
    "        img_type_dic[img_name], num_people_dic[img_name], location_dic[img_name], obj_list_dic[img_name]\n",
    "    )\n",
    "\n",
    "    # Generate the caption using the language model\n",
    "    caption_texts = flan_manager.generate_response(num_captions * [prompt_dic[img_name]], model_params)\n",
    "\n",
    "    # Zero-shot VLM: rank captions.\n",
    "    caption_feats = clip_manager.get_text_feats(caption_texts)\n",
    "    sorted_captions, caption_scores = clip_manager.get_nn_text(caption_texts, caption_feats, img_feat_dic[img_name])\n",
    "    sorted_caption_map[img_name] = sorted_captions\n",
    "    caption_score_map[img_name] = dict(zip(sorted_captions, caption_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260f29b",
   "metadata": {},
   "source": [
    "### Save the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6673b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for img_name in img_dic:\n",
    "    generated_caption = sorted_caption_map[img_name][0]\n",
    "    data_list.append({\n",
    "        'image_name': img_name,\n",
    "        'image_path': img_paths[img_name],\n",
    "        'generated_caption': generated_caption,\n",
    "        'cosine_similarity': caption_score_map[img_name][generated_caption]\n",
    "    })\n",
    "pd.DataFrame(data_list).to_csv(f'{approach}_outputs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0af0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
